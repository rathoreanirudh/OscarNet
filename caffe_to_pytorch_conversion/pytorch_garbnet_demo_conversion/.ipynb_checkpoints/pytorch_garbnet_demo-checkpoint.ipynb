{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import caffe\n",
    "import os\n",
    "from pylab import *\n",
    "import sys\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'SpotGarbage_GarbNet/garbnet_mean.binaryproto'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-43cb81141250>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcaffemodel_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'SpotGarbage_GarbNet/garbnet_fcn.caffemodel'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcaffe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaffe_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBlobProto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFromString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmean\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mcaffe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblobproto_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'SpotGarbage_GarbNet/garbnet_mean.binaryproto'"
     ]
    }
   ],
   "source": [
    "mean_filename='SpotGarbage_GarbNet/garbnet_mean.binaryproto'\n",
    "deploy_filename = 'SpotGarbage_GarbNet/deploy_garbnet.prototxt'\n",
    "caffemodel_file = 'SpotGarbage_GarbNet/garbnet_fcn.caffemodel'\n",
    "\n",
    "proto_data = open(mean_filename, \"rb\").read()\n",
    "a = caffe.io.caffe_pb2.BlobProto.FromString(proto_data)\n",
    "mean  = caffe.io.blobproto_to_array(a)[0]\n",
    "\n",
    "net = caffe.Net(deploy_filename,caffemodel_file,caffe.TEST)\n",
    "for item,blob in net.params.items():\n",
    "    print(item,blob[0].data.shape)\n",
    "    \n",
    "print('\\n')\n",
    "for item,blob in net.blobs.items():\n",
    "    print(item,blob.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../SpotGarbage_GarbNet/pytorch_garbnet.py'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-cdc6f5c21c17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mMainModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_source\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'MainModel'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"../SpotGarbage_GarbNet/pytorch_garbnet.py\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mthe_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SpotGarbage_GarbNet/pytorch_garbnet.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/imp.py\u001b[0m in \u001b[0;36mload_source\u001b[0;34m(name, pathname, file)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_exec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m     \u001b[0;31m# To allow reloading to potentially work, use a non-hacked loader which\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;31m# won't rely on a now-closed file object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(spec)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_code\u001b[0;34m(self, fullname)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/imp.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    155\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(self, path)\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../SpotGarbage_GarbNet/pytorch_garbnet.py'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import imp\n",
    "MainModel = imp.load_source('MainModel', \"../SpotGarbage_GarbNet/pytorch_garbnet.py\")\n",
    "\n",
    "the_model = torch.load(\"SpotGarbage_GarbNet/pytorch_garbnet.pth\")\n",
    "the_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def load_dataset(path):\n",
    "    #1.resize for the network 277x277 (as garbdemo instructed)\n",
    "    #2.convert to tensor (gpu array)\n",
    "    #3.will normalize data between -1 and 1\n",
    "    transform = torchvision.transforms.Compose(\n",
    "                    [torchvision.transforms.Resize((277,277)),\n",
    "                    torchvision.transforms.ToTensor(),\n",
    "                     torchvision.transforms.Normalize(\n",
    "                         (108.39786852, 115.89358715, 119.99467375), (1.0, 1.0, 1.0)\n",
    "                     )\n",
    "                    ])\n",
    "    \n",
    "    #to import images from the disk\n",
    "    dataset = torchvision.datasets.ImageFolder(\n",
    "        root=path,\n",
    "        transform=transform\n",
    "    )\n",
    "    \n",
    "    #creates an iterable for the dataset to use in a forloop\n",
    "    dataset_loader = torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        num_workers=2,\n",
    "        shuffle=False\n",
    "    )\n",
    "    return dataset_loader\n",
    "\n",
    "'''\n",
    "image directory must be in the same location of this script\n",
    "images/garbage/img0.jpg,img1.jpg,img2.jpg\n",
    "images/notgarbage/img3.jpg,img4.jpg\n",
    "\n",
    "pytorch will label the classes based on the number of folders there are.\n",
    "garbage is folder 0 so class label is 0\n",
    "notgarbage is folder 1 so class label is 1\n",
    "\n",
    "only need the directory where all class folders are for argument\n",
    "'''\n",
    "dataset = load_dataset('images/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Labels: \\n 0.Garbage \\n 1.Not Garbage\\n')\n",
    "for data, target in dataset:\n",
    "    #prints [batchsize, channel size (RGB->3), height, width], label \n",
    "    print('Tensor (image to array) size: ', data.size(), 'Target label: ', target,end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "\n",
    "for data, target in dataset:\n",
    "    pred = the_model(data)\n",
    "    print(pred)\n",
    "    print(pred.argmax(), target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gatherImages(folder,imageNames=None):\n",
    "    images = []\n",
    "    names = []\n",
    "    files = os.listdir(folder)\n",
    "    total = len(files)\n",
    "    #print('Total %d images in folder %s' % (total,folder))\n",
    "    for i in os.listdir(folder):\n",
    "        try:\n",
    "            if imageNames is None or i in imageNames:\n",
    "                example_image = folder+'/'+i\n",
    "                input_image = Image.open(example_image)\n",
    "                images.append(input_image)\n",
    "                names.append(i)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    return images,names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def resizeForFCN(image,size):\n",
    "    w,h = image.size\n",
    "    if w<h:\n",
    "        return image.resize((int(227*size),int((227*h*size)/w))) #227x227 is input for regular CNN\n",
    "    else:\n",
    "        return image.resize((int((227*w*size)/h),int(227*size)))\n",
    "    \n",
    "def getSegmentedImage(test_image, probMap,thresh):\n",
    "    kernel = np.ones((6,6),np.uint8)\n",
    "    wt,ht = test_image.size\n",
    "    out_bn = np.zeros((ht,wt),dtype=uint8)\n",
    "    res = 0\n",
    "    for h in range(probMap.shape[0]):\n",
    "        \n",
    "        for k in range(probMap.shape[1]):\n",
    "            if probMap[h,k] > thresh:\n",
    "                res += 1\n",
    "                x1 = h*62 #stride 2 at fc6_gb_conv equivalent to 62 pixels stride in input\n",
    "                y1 = k*62\n",
    "                for hoff in range(x1,227+x1):\n",
    "                    if hoff < out_bn.shape[0]:\n",
    "                        for koff in range(y1,227+y1):\n",
    "                            if koff < out_bn.shape[1]:\n",
    "                                out_bn[hoff,koff] = 255\n",
    "    print(\"count \",res)\n",
    "    edge = cv2.Canny(out_bn,200,250)\n",
    "    box = cv2.dilate(edge,kernel,iterations = 3)\n",
    "    \n",
    "    or_im_ar = np.array(test_image)\n",
    "    or_im_ar[:,:,1] = (or_im_ar[:,:,1] | box)\n",
    "    or_im_ar[:,:,2] = or_im_ar[:,:,2] * box + or_im_ar[:,:,2]\n",
    "    or_im_ar[:,:,0] = or_im_ar[:,:,0] * box + or_im_ar[:,:,0]\n",
    "    \n",
    "    return Image.fromarray(or_im_ar)\n",
    "    \n",
    "    \n",
    "def getPredictionsFor(images,names,size,thresh,output_folder):\n",
    "    for i in range(len(images)):\n",
    "#         try:\n",
    "            test_image = resizeForFCN(images[i],size)\n",
    "            \n",
    "            in_ = np.array(test_image,dtype = np.float32)\n",
    "            in_ = in_[:,:,::-1]\n",
    "            print('min before scaling',np.amin(in_))\n",
    "            print('max before scaling',np.amax(in_))\n",
    "            in_ -= np.array(mean.mean(1).mean(1))\n",
    "            print('mean scaling', np.array(mean.mean(1).mean(1)))\n",
    "            print('min after scaling',np.amin(in_))\n",
    "            print('max after scaling',np.amax(in_))\n",
    "            in_ = in_.transpose((2,0,1))\n",
    "            if i ==0:\n",
    "                print(in_)\n",
    "            #print('in_',in_)\n",
    "            net.blobs['data'].reshape(1,*in_.shape)\n",
    "            net.blobs['data'].data[...] = in_\n",
    "            net.forward()\n",
    "            #print(net.blobs['prob'].data[0,1])\n",
    "            probMap =net.blobs['prob'].data[0,1]\n",
    "            print('probmap: ',probMap.shape)\n",
    "            print( names[i]+'...',)\n",
    "            if len(np.where(probMap>thresh)[0]) > 0:\n",
    "                print( 'Garbage!')\n",
    "            else:\n",
    "                print('Not Garbage!')\n",
    "            \n",
    "            out_ = getSegmentedImage(test_image, probMap,thresh)\n",
    "            out_.save(output_folder + '/output_' + names[i])\n",
    "#         except:\n",
    "#             pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify 'input' folder containing images for prediction\n",
    "images,names = gatherImages('images/garbage')\n",
    "print(images[0])\n",
    "#images[0].show()\n",
    "#specify 'output' folder to store segmented predictions\n",
    "getPredictionsFor(images,names,4,0.999,'output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(Image.open('input/sample_2_garbage.jpg'))\n",
    "figure()\n",
    "imshow(Image.open('output/output_sample_2_garbage.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
